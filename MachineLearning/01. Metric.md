## **알고있는 metric에 대해 설명해주세요.**

### **개념**
- Metrics(척도)
    - 어떤 모델을 평가하기 위해서 사용하는 값.
    - 손실함수와 비교
        - 손실함수는 모델의 성능을 끌어올리기 위해 참조하는 값으로 학습과정에서 가중치 및 편향의 upgrade에 참고하는 값
        - Metrics(척도)는 결과적인 모델의 성능을 의미
- Metrics의 종류
    - 정확도, 정밀도, 재현율
        - 의미
            - 예측한 값이 맞는 경우 : $TP\;TN$
                - $TP$ : (실제) positive (예측) positive
                - $TN$: (실제) negative (예측) negative
            - 예측한 값이 틀린 경우: $FP \; FN$
                - $FP$: (실제) negative (예측) positive
                - $FN$: (실제) positive (예측) negative
        - **정확도(Accuracy)**
            - $Accuracy= (TP+TN) / (TP+FP+FN+TN)$
            - 타겟 대비 정확히 예측한 비율
        - **정밀도(Precision)**
            - $Precision = TP / (TP+FP)$
            - 모델이 Positive로 예측한 것 중 실제로 Positive인 비율
        - **재현율(Recall)**
            - $Recall = TP / (TP + FN)$
            - 실제 Positive인 것 중 모델이 Positive로 예측한 비율
    - **F1 Score**
        - $F_1Score=2*\frac{Precision * Recall}{Precision + Recall }$
        - Precision(정밀도)와 Recall(재현율)의 조화평균(Harmonic Mean)을 나타내는 것
        - 특이값의 리스크를 회피할 수 있음.
    - **Regression Metrics** **회귀 메트릭**
        - **MSE(Mean Squared Error)**
            - $\frac{1}{N} \sum_{i=1}^N(y_i- \widehat{y_i})^2$
            - 실제값과 오차의 차를 제곱한 뒤 평균한 값
        - **RMSE(Root Mean Squared Error)**
            - $\sqrt{ \frac{1}{N} \sum_{i=1}^N(y_i- \widehat{y_i})^2 }$
            - 단순 오차제곱합의 오차율 값이 큰 것을 루트 연산을 통해 보정
        - **R-squared(R2)**
            - $R^2=1- \frac{SS_{RES}}{SS_{TOT}}=1- \frac{ \sum(y_i- \widehat{y}_i)^2}{ \sum (y_i- \overline{y})^2 }$
            - 총제곱합(SST)에 대한 회귀제곱합
            - **결정계수**라고도 불리며 **변동량(분산)에서 현재 적용 모델이 설명할 수 있는 부분의 비율을 의미**
            - 예측의 적합도를 0과 1사이의 값으로 계산하고, 1에 가까울수록 설명력이 높음.
        - **MAE(Mean Absolute Error)**
            - $\frac{1}{N} \sum_{i=1}^N|y_i- \widehat{y_i}|$
            - 실제값과 예측값의 차이의 절대값 합의 평균
            - Outliear의 영향을 받지 않음.
            - MSE와 달리 특이값에 robust를 적용해 영향을 적게 받아, 특이값이 있는 경우에 주로 사용됨.